{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cff8686",
   "metadata": {},
   "source": [
    "## 第四章 基础实战——FashionMNIST时装分类\n",
    "\n",
    "经过前面三章内容的学习，我们完成了以下的内容：\n",
    "\n",
    "   对PyTorch有了初步的认识\n",
    "   学会了如何安装PyTorch以及对应的编程环境\n",
    "   学习了PyTorch最核心的理论基础（张量&自动求导）\n",
    "   梳理了利用PyTorch完成深度学习的主要步骤和对应实现方式\n",
    "   现在，我们通过一个基础实战案例，将第一部分所涉及的PyTorch入门知识串起来，便于大家加深理解。同时为后续的进阶学习打好基础。\n",
    "\n",
    "我们这里的任务是对10个类别的“时装”图像进行分类，使用FashionMNIST数据集（https://github.com/zalandoresearch/fashion-mnist ）。上图给出了FashionMNIST中数据的若干样例图，其中每个小图对应一个样本。\n",
    "FashionMNIST数据集中包含已经预先划分好的训练集和测试集，其中训练集共60,000张图像，测试集共10,000张图像。每张图像均为单通道黑白图像，大小为32*32pixel，分属10个类别。\n",
    "\n",
    "下面让我们一起将第三章各部分内容逐步实现，来跑完整个深度学习流程。\n",
    "\n",
    "## 首先导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "818913b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58522a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置训练环境和超参数\n",
    "# 方案一：使用os.environ\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# 方案而使用device，后续对要使用GPU 的变量用.to(device)即可\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 配置其他超参数，如batch_size,num_workers, learning rate,以及总的epochs\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "lr =1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d5be4",
   "metadata": {},
   "source": [
    "## 数据读入和加载\n",
    "这里同时展示两种方式:\n",
    "\n",
    "下载并使用PyTorch提供的内置数据集\n",
    "从网站下载以csv格式存储的数据，读入并转成预期的格式\n",
    "第一种数据读入方式只适用于常见的数据集，如MNIST，CIFAR10等，PyTorch官方提供了数据下载。这种方式往往适用于快速测试方法（比如测试下某个idea在MNIST数据集上是否有效）\n",
    "第二种数据读入方式需要自己构建Dataset，这对于PyTorch应用于自己的工作中十分重要\n",
    "同时，还需要对数据进行必要的变换，比如说需要将图片统一为一致的大小，以便后续能够输入网络训练；需要将数据格式转为Tensor类，等等。\n",
    "\n",
    "这些变换可以很方便地借助torchvision包来完成，这是PyTorch官方用于图像处理的工具库，上面提到的使用内置数据集的方式也要用到。PyTorch的一大方便之处就在于它是一整套“生态”，有着官方和第三方各个领域的支持。这些内容我们会在后续课程中详细介绍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5041eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先设置数据变换\n",
    "from torchvision import transforms\n",
    "\n",
    "image_size = [28,28]\n",
    "data_transform = transforms.Compose([\n",
    "    #transforms.ToPILImage(),   # 这一步取决于后续的数据读取方式，如果使用内置数据集则不需要\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff71a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取方式一：使用torchvision自带数据集，下载可能需要一段时间\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='./', train=True, download=True, transform=data_transform)\n",
    "test_data = datasets.FashionMNIST(root='./', train=False, download=True, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f06535",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取方式二：读入csv格式的数据，自行构建Dataset类,能够被模型训练的数据\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.images = df.iloc[:,1:].values.astype(np.unit8)\n",
    "        self.labels = df.iloc[:,0].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    def __getitem__(self,idx):\n",
    "        image = self.images[idx].reshape(28,28,1)\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image/255, dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "# 自己手动下载数据，然将数据进行转换    \n",
    "train_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_test.csv\")\n",
    "train_data = FMDataset(train_df, data_transform)\n",
    "test_data = FMDataset(test_df, data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3c5d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在构建训练和测试数据集完成后，需要定义DataLoader类，以便在训练和测试时加载数据\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58961df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入后，我们可以做一些数据可视化操作，主要是验证我们读入的数据是否正确\n",
    "import matplotlib.pyplot as plt\n",
    "image, label = next(iter(train_loader))\n",
    "print(image.shape, label.shape)\n",
    "plt.imshow(image[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f453e7",
   "metadata": {},
   "source": [
    "##  模型设计\n",
    "由于任务较为简单，这里我们手搭一个CNN，而不考虑当下各种模型的复杂结构\n",
    "模型构建完成后，将模型放到GPU上用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33c5969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "        nn.Conv2d(1,32,5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,stride=2),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Conv2d(32, 64, 5),\n",
    "        nn.ReLU(),    \n",
    "        nn.MaxPool2d(2,stride=2),\n",
    "        nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "        nn.Linear(64*4*4, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "model = Net()\n",
    "\n",
    "#model = model.cuda()\n",
    "# model = nn.DataParallel(model).cuda()   # 多卡训练时的写法，之后的课程中会进一步讲解       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad9603",
   "metadata": {},
   "source": [
    "## 设定损失函数\n",
    "使用torch.nn模块自带的CrossEntropy损失\n",
    "PyTorch会自动把整数型的label转为one-hot型，用于计算CE loss\n",
    "这里需要确保label是从0开始的，同时模型不加softmax层（使用logits计算）,这也说明了PyTorch训练中各个部分不是独立的，需要通盘考虑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d275faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0cac4",
   "metadata": {},
   "source": [
    "## 设定优化器\n",
    "这里我们使用Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63637f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c11d68",
   "metadata": {},
   "source": [
    "## 训练和测试（验证）\n",
    "各自封装成函数，方便后续调用\n",
    "关注两者的主要区别：\n",
    "\n",
    "模型状态设置\n",
    "是否需要初始化优化器\n",
    "是否需要将loss传回到网络\n",
    "是否需要每步更新optimizer\n",
    "此外，对于测试或验证过程，可以计算分类准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8e5f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, label in train_loader:\n",
    "        data, label = data, label\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)  # .item()将loss张量转换成唯一值标量，方面求均值\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6562e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):       \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data, label = data, label\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output, 1)  # 求出概率最大那部分\n",
    "            gt_labels.append(label.cpu().data.numpy())\n",
    "            pred_labels.append(preds.cpu().data.numpy())\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "    val_loss = val_loss/len(test_loader.dataset)\n",
    "    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cc9664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.644116\n",
      "Epoch: 1 \tValidation Loss: 0.428405, Accuracy: 0.851600\n",
      "Epoch: 2 \tTraining Loss: 0.399351\n",
      "Epoch: 2 \tValidation Loss: 0.343910, Accuracy: 0.875900\n",
      "Epoch: 3 \tTraining Loss: 0.344591\n",
      "Epoch: 3 \tValidation Loss: 0.313032, Accuracy: 0.886200\n",
      "Epoch: 4 \tTraining Loss: 0.314307\n",
      "Epoch: 4 \tValidation Loss: 0.308780, Accuracy: 0.887700\n",
      "Epoch: 5 \tTraining Loss: 0.294836\n",
      "Epoch: 5 \tValidation Loss: 0.294369, Accuracy: 0.893700\n",
      "Epoch: 6 \tTraining Loss: 0.275417\n",
      "Epoch: 6 \tValidation Loss: 0.265742, Accuracy: 0.903100\n",
      "Epoch: 7 \tTraining Loss: 0.264969\n",
      "Epoch: 7 \tValidation Loss: 0.268094, Accuracy: 0.901700\n",
      "Epoch: 8 \tTraining Loss: 0.254130\n",
      "Epoch: 8 \tValidation Loss: 0.252261, Accuracy: 0.912100\n",
      "Epoch: 9 \tTraining Loss: 0.242073\n",
      "Epoch: 9 \tValidation Loss: 0.255134, Accuracy: 0.905100\n",
      "Epoch: 10 \tTraining Loss: 0.235097\n",
      "Epoch: 10 \tValidation Loss: 0.239395, Accuracy: 0.915000\n",
      "Epoch: 11 \tTraining Loss: 0.223144\n",
      "Epoch: 11 \tValidation Loss: 0.231490, Accuracy: 0.916600\n",
      "Epoch: 12 \tTraining Loss: 0.216449\n",
      "Epoch: 12 \tValidation Loss: 0.232626, Accuracy: 0.916500\n",
      "Epoch: 13 \tTraining Loss: 0.208205\n",
      "Epoch: 13 \tValidation Loss: 0.229877, Accuracy: 0.916400\n",
      "Epoch: 14 \tTraining Loss: 0.205687\n",
      "Epoch: 14 \tValidation Loss: 0.224810, Accuracy: 0.917300\n",
      "Epoch: 15 \tTraining Loss: 0.195827\n",
      "Epoch: 15 \tValidation Loss: 0.222901, Accuracy: 0.921600\n",
      "Epoch: 16 \tTraining Loss: 0.192750\n",
      "Epoch: 16 \tValidation Loss: 0.223022, Accuracy: 0.921500\n",
      "Epoch: 17 \tTraining Loss: 0.186664\n",
      "Epoch: 17 \tValidation Loss: 0.233679, Accuracy: 0.916500\n",
      "Epoch: 18 \tTraining Loss: 0.181079\n",
      "Epoch: 18 \tValidation Loss: 0.214848, Accuracy: 0.925500\n",
      "Epoch: 19 \tTraining Loss: 0.179931\n",
      "Epoch: 19 \tValidation Loss: 0.217246, Accuracy: 0.923200\n",
      "Epoch: 20 \tTraining Loss: 0.170598\n",
      "Epoch: 20 \tValidation Loss: 0.218010, Accuracy: 0.921400\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    val(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20712e0d",
   "metadata": {},
   "source": [
    "## 模型保存\n",
    "训练完成后，可以使用torch.save保存模型参数或者整个模型，也可以在训练过程中保存模型\n",
    "这部分会在后面的课程中详细介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33c20b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\bianbian_ML\\lib\\site-packages\\torch\\serialization.py:359: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./FahionModel.pkl\"\n",
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00a28e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bianbian_ML] *",
   "language": "python",
   "name": "conda-env-bianbian_ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
