{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "197175de",
   "metadata": {},
   "source": [
    "# 模型构建\n",
    "## 1.1神经网络的构造\n",
    "PyTorch中神经网络构造一般是基于 Module 类的模型来完成的，它让模型构造更加灵活。\n",
    "\n",
    "Module 类是 nn 模块里提供的一个模型构造类，是所有神经⽹网络模块的基类，我们可以继承它来定义我们想要的模型。下面继承 Module 类构造多层感知机。这里定义的 MLP 类重载了 Module 类的 init 函数和 forward 函数。它们分别用于创建模型参数和定义前向计算。前向计算也即正向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7d1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class MLP(nn.Module):\n",
    "    # 声明带有模型参数的层，这里声明了两个全连接层\n",
    "    def __init__(self, **kwargs):\n",
    "        # 调用MLP父类Block的构造函数来进行必要的初始化，这样在构造实列时还可以指定其他函数\n",
    "        super (MLP,self).__init__(**kwargs)\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(256,10)\n",
    "    def forward(self, x):\n",
    "        o = self.act(self.hidden(x))\n",
    "        return self.output(o)\n",
    "\n",
    "# 以上的 MLP 类中⽆无须定义反向传播函数。系统将通过⾃动求梯度⽽自动⽣成反向传播所需的 backward 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f2bb6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1406, -0.0965, -0.0957, -0.2029,  0.0289,  0.1059,  0.2033, -0.1956,\n",
       "         -0.0934,  0.0157],\n",
       "        [-0.2899,  0.0370, -0.0224,  0.0294, -0.0796,  0.0902,  0.1315, -0.3126,\n",
       "          0.0600,  0.1092]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "我们可以实例化 MLP 类得到模型变量 net 。\n",
    "下⾯的代码初始化 net 并传入输⼊数据 X 做一次前向计算。\n",
    "其中， net(X) 会调用 MLP 继承⾃自 Module 类的 call 函数，这个函数将调⽤用 MLP 类定义的forward 函数来完成前向计算。\n",
    "\"\"\"\n",
    "X = torch.rand(2,784)\n",
    "net = MLP()\n",
    "print(net)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae1cce0",
   "metadata": {},
   "source": [
    "## 1.2 神经网络常见的层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a386e6d",
   "metadata": {},
   "source": [
    "### 不含模型参数的层\n",
    "我们先介绍如何定义一个不含模型参数的自定义层。下⾯构造的 MyLayer 类通过继承 Module 类自定义了一个将输入减掉均值后输出的层，并将层的计算定义在了 forward 函数里。这个层里不含模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "376faa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    def forward(self, x):\n",
    "        return x - x.mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e9ba761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试，实例化该层，然后做前向计算\n",
    "layer = MyLayer()\n",
    "layer(torch.tensor([1, 2, 3, 4, 5], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2cc68b",
   "metadata": {},
   "source": [
    "## 含模型参数的层\n",
    "我们还可以自定义含模型参数的自定义层。其中的模型参数可以通过训练学出。\n",
    "\n",
    "Parameter 类其实是 Tensor 的子类，如果一 个 Tensor 是 Parameter ，那么它会⾃动被添加到模型的参数列表里。所以在⾃定义含模型参数的层时，我们应该将参数定义成 Parameter ，除了直接定义成 Parameter 类外，还可以使⽤ ParameterList 和 ParameterDict 分别定义参数的列表和字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aa8c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyListDense(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyListDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyListDense, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "        self.params.append(nn.Parameter(torch.randn(4, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.params)):\n",
    "            x = torch.mm(x, self.params[i])\n",
    "        return x\n",
    "net = MyListDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee7af6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDictDense(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyDictDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDictDense, self).__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "                'linear1': nn.Parameter(torch.randn(4, 4)),\n",
    "                'linear2': nn.Parameter(torch.randn(4, 1))\n",
    "        })\n",
    "        self.params.update({'linear3': nn.Parameter(torch.randn(4, 2))}) # 新增\n",
    "\n",
    "    def forward(self, x, choice='linear1'):\n",
    "        return torch.mm(x, self.params[choice])\n",
    "\n",
    "net = MyDictDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd0759",
   "metadata": {},
   "source": [
    "## 二维卷积层\n",
    "二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不不断迭代卷积核和偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c463f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积运算（二维互相关）\n",
    "def corr2d(X, K): \n",
    "    h, w = K.shape\n",
    "    X, K = X.float(), K.float()\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "# 二维卷积层\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "290981eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量量⼤大⼩小和通道数\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:]) # 排除不关心的前两维:批量和通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4300b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意这里是两侧分别填充1⾏或列，所以在两侧一共填充2⾏或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3,padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f5ef9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa67d187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当卷积核的高和宽不同时，我们也可以通过设置高和宽上不同的填充数使输出和输入具有相同的高和宽。\n",
    "# 使⽤用高为5、宽为3的卷积核。在⾼和宽两侧的填充数分别为2和1\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd21b356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在二维互相关运算中，卷积窗口从输入数组的最左上方开始，按从左往右、从上往下 的顺序，依次在输⼊数组上滑动。我们将每次滑动的行数和列数称为步幅(stride)。\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1df46a",
   "metadata": {},
   "source": [
    "### 池化层\n",
    "池化层每次对输入数据的一个固定形状窗口(⼜称池化窗口)中的元素计算输出。\n",
    "不同于卷积层里计算输⼊和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。\n",
    "该运算也 分别叫做最大池化或平均池化。在二维最⼤池化中，池化窗⼝口从输⼊入数组的最左上⽅方开始，按从左往右、从上往下的顺序，依次在输⼊数组上滑动。\n",
    "当池化窗口滑动到某⼀位置时，窗口中的输入子数组的最大值即输出数组中相应位置的元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "234e65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = np.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991506f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 5.],\n",
       "       [7., 8.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7bce13",
   "metadata": {},
   "source": [
    "我们可以使用torch.nn包来构建神经网络。我们已经介绍了autograd包，nn包则依赖于autograd包来定义模型并对它们求导。一个nn.Module包含各个层和一个forward(input)方法，该方法返回output。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6d96e",
   "metadata": {},
   "source": [
    "## 模型实例\n",
    "LeNet\n",
    "这是一个简单的前馈神经网络 (feed-forward network）（LeNet）。它接受一个输入，然后将它送入下一层，一层接一层的传递，最后给出输出。\n",
    "\n",
    "一个神经网络的典型训练过程如下：\n",
    "\n",
    "    1、定义包含一些可学习参数(或者叫权重）的神经网络\n",
    "    \n",
    "    2、在输入数据集上迭代\n",
    "    \n",
    "    3、通过网络处理输入\n",
    "    \n",
    "    4、计算 loss (输出和正确答案的距离）\n",
    "    \n",
    "    5、将梯度反向传播给网络的参数\n",
    "    \n",
    "    6、更新网络的权重，一般使用一个简单的规则：weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39dd83b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F     \n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 输入图像channel：1；输出channel：6；5x5卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2x2 Max pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # 如果是方阵,则可以只使用一个数字进行定义\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # 除去批处理维度的其他所有维度\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3363f014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-0.0620, -0.1959, -0.1627,  0.0922,  0.1768],\n",
      "          [ 0.0109,  0.1396, -0.1091, -0.1960, -0.1479],\n",
      "          [ 0.0686,  0.0327,  0.1337,  0.0159, -0.0910],\n",
      "          [ 0.0693, -0.0473, -0.0203, -0.1077,  0.1562],\n",
      "          [ 0.1144,  0.0516, -0.0399,  0.0815,  0.0845]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0114,  0.0929, -0.1989, -0.1230, -0.1988],\n",
      "          [ 0.0386, -0.0825,  0.0152, -0.1988,  0.1403],\n",
      "          [ 0.0117,  0.0310, -0.1973,  0.0063,  0.0980],\n",
      "          [-0.1326, -0.1611, -0.1819,  0.1835,  0.1650],\n",
      "          [-0.1079, -0.0611,  0.1465, -0.1274,  0.0321]]],\n",
      "\n",
      "\n",
      "        [[[-0.0262, -0.1816,  0.1965, -0.0419, -0.0811],\n",
      "          [ 0.1216, -0.1067, -0.1005,  0.1886,  0.0305],\n",
      "          [ 0.0693,  0.0740, -0.0422,  0.0075,  0.1308],\n",
      "          [ 0.1275, -0.1373,  0.0181,  0.1619,  0.0820],\n",
      "          [-0.1370,  0.1996,  0.1725,  0.1193,  0.1592]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1046, -0.1576,  0.1546, -0.1053, -0.1332],\n",
      "          [ 0.1963,  0.1590,  0.0171, -0.1450, -0.0335],\n",
      "          [ 0.1563, -0.0072,  0.0058,  0.1365, -0.1109],\n",
      "          [-0.0358,  0.1436, -0.1069,  0.0185, -0.1973],\n",
      "          [ 0.0850, -0.0161, -0.0573, -0.0472, -0.1530]]],\n",
      "\n",
      "\n",
      "        [[[-0.0540,  0.1800,  0.0602, -0.1987,  0.0669],\n",
      "          [-0.1630,  0.1943,  0.1266,  0.0505,  0.0143],\n",
      "          [ 0.1146,  0.0916,  0.1546,  0.0186, -0.1322],\n",
      "          [-0.0216,  0.1665,  0.0763, -0.1380,  0.0258],\n",
      "          [-0.0045, -0.0888, -0.0039, -0.1670,  0.1693]]],\n",
      "\n",
      "\n",
      "        [[[-0.1129, -0.0515, -0.1073,  0.1820,  0.1678],\n",
      "          [-0.1697,  0.0342, -0.1446,  0.0787,  0.0142],\n",
      "          [ 0.1425,  0.1160,  0.0259,  0.1406, -0.0379],\n",
      "          [ 0.1366,  0.1237,  0.1015, -0.0556, -0.0343],\n",
      "          [-0.0198,  0.0997,  0.1717,  0.1363, -0.1017]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1989, -0.0992,  0.1263,  0.0456,  0.1166,  0.0203],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 6.7114e-02,  2.6292e-02, -1.9799e-02, -6.8988e-02, -5.3487e-02],\n",
      "          [ 2.8751e-02,  5.2943e-02,  6.2484e-02, -7.3224e-02, -7.9200e-02],\n",
      "          [ 6.9112e-02, -3.7971e-02,  4.7582e-02, -6.5433e-03,  5.9803e-02],\n",
      "          [ 6.8148e-02, -1.1891e-03, -7.5185e-02,  6.8576e-02, -5.9806e-02],\n",
      "          [-2.5894e-02,  3.6251e-02,  6.3525e-03, -5.1943e-02,  3.0717e-02]],\n",
      "\n",
      "         [[-7.7840e-02, -6.5328e-02,  3.8183e-02,  4.6195e-02,  4.8123e-02],\n",
      "          [ 7.1024e-02,  3.2704e-02, -5.4403e-02,  1.2926e-03,  4.5480e-02],\n",
      "          [ 3.0243e-02, -5.2203e-02,  6.0707e-02, -1.3192e-02,  4.5100e-02],\n",
      "          [ 3.3942e-02, -1.2490e-02, -8.1461e-02,  7.1118e-02,  3.5287e-02],\n",
      "          [ 6.5032e-02, -3.1480e-02, -7.9208e-02, -6.7222e-03,  1.8023e-02]],\n",
      "\n",
      "         [[-7.2129e-02,  7.6458e-02,  4.1022e-02,  6.5756e-03,  8.0201e-02],\n",
      "          [ 5.2700e-02, -8.2346e-03, -7.3861e-02, -7.2218e-02, -2.1122e-02],\n",
      "          [-8.1412e-02, -2.7858e-02,  1.9629e-02, -1.4388e-02, -4.7517e-02],\n",
      "          [ 1.3566e-02, -2.9900e-02, -5.6888e-02,  6.0587e-02, -2.2826e-02],\n",
      "          [ 7.9376e-02, -5.6715e-02,  7.4409e-02, -2.5099e-02, -5.4920e-02]],\n",
      "\n",
      "         [[-3.0530e-02, -2.0310e-02, -8.0078e-02,  1.2797e-02,  1.9100e-02],\n",
      "          [-7.0725e-02, -6.6679e-02, -5.5409e-02,  5.9138e-02,  4.1199e-02],\n",
      "          [ 6.9463e-02,  6.4761e-02, -1.0488e-02,  6.5320e-02,  5.3017e-02],\n",
      "          [ 1.5433e-02, -6.5502e-02,  2.3362e-02, -1.3288e-02,  2.8992e-02],\n",
      "          [-1.9721e-02,  5.3137e-02, -6.5565e-02,  3.7338e-03, -1.4523e-03]],\n",
      "\n",
      "         [[-6.4776e-02,  1.8572e-02, -2.6874e-02,  2.7970e-02, -5.2429e-04],\n",
      "          [-3.0717e-02, -8.7879e-03,  7.8500e-02,  5.5744e-02,  6.1032e-02],\n",
      "          [ 8.1173e-02,  2.3240e-02, -4.5872e-02, -3.2492e-02,  6.7480e-02],\n",
      "          [ 1.4116e-02, -4.9916e-02,  7.9877e-02, -6.1759e-02, -6.1973e-02],\n",
      "          [ 4.4457e-02, -3.6430e-02, -1.4254e-02, -4.2921e-03, -7.2001e-02]],\n",
      "\n",
      "         [[ 6.7866e-03,  4.4985e-02,  3.9523e-02,  7.3969e-03, -1.2262e-02],\n",
      "          [ 1.1925e-02,  3.1768e-02, -5.3226e-02, -3.7265e-02, -1.7596e-03],\n",
      "          [ 1.3807e-02, -4.3993e-02, -2.7957e-02, -7.5270e-02, -1.2292e-02],\n",
      "          [ 2.1842e-02, -4.3335e-02,  1.5689e-02,  7.1334e-02,  1.2912e-02],\n",
      "          [ 6.0718e-02,  7.2472e-02,  4.1460e-02,  5.6404e-02,  8.0663e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6819e-02, -7.6837e-03, -1.1849e-02, -3.6035e-02,  5.7494e-02],\n",
      "          [-7.2283e-02, -2.2027e-02,  2.0720e-02,  4.2488e-02,  1.9265e-02],\n",
      "          [-5.7940e-03,  1.5661e-05, -8.1158e-02, -7.0717e-04, -5.1257e-02],\n",
      "          [ 6.8034e-02, -3.6262e-02, -6.3587e-03,  5.2924e-03, -1.1106e-02],\n",
      "          [-6.1174e-02,  3.6169e-03,  5.5873e-02,  1.5634e-02,  4.9024e-02]],\n",
      "\n",
      "         [[ 3.4350e-02, -5.6927e-02,  4.9410e-02, -5.0204e-02,  5.8690e-02],\n",
      "          [-6.8971e-02,  7.7793e-02, -6.9728e-03,  4.4420e-02,  1.6653e-02],\n",
      "          [-7.9104e-03,  3.4087e-02, -7.0776e-02, -3.8177e-02,  1.8210e-02],\n",
      "          [ 2.2175e-02, -3.9643e-02,  5.5704e-02, -6.6408e-02,  1.4994e-02],\n",
      "          [ 4.5739e-02,  1.0404e-03,  1.4715e-02, -1.7697e-02,  6.0868e-02]],\n",
      "\n",
      "         [[ 6.0673e-03,  3.9766e-02, -2.8198e-02,  5.9662e-02,  6.4400e-02],\n",
      "          [ 7.8963e-02, -3.5302e-02,  7.4631e-02,  1.3238e-02, -3.9422e-02],\n",
      "          [ 6.9049e-02,  5.3710e-02,  7.4505e-02,  7.5172e-02, -7.7882e-02],\n",
      "          [-5.4740e-02, -5.1405e-02, -9.8150e-03, -1.8495e-02,  1.5877e-02],\n",
      "          [-1.4435e-02, -5.4418e-03, -3.9832e-02, -4.7909e-02, -1.8082e-03]],\n",
      "\n",
      "         [[-2.9923e-02, -3.5703e-02,  6.4485e-02, -2.8223e-02, -5.4338e-04],\n",
      "          [ 4.8851e-02, -4.9374e-02, -1.0275e-02, -1.1044e-02, -1.5540e-02],\n",
      "          [ 4.6517e-02,  5.8024e-02,  5.6174e-02,  4.1352e-02,  4.7695e-02],\n",
      "          [-1.3817e-02,  1.8207e-02, -3.9883e-02,  2.3881e-02,  1.8740e-02],\n",
      "          [ 1.9689e-02, -3.2900e-02,  2.5205e-02,  1.8677e-02, -6.6706e-03]],\n",
      "\n",
      "         [[ 5.1217e-02, -1.1189e-02,  2.2462e-02, -7.7028e-02, -7.6449e-02],\n",
      "          [ 5.3172e-02,  8.0549e-02, -1.4394e-02,  3.3873e-02,  3.6531e-03],\n",
      "          [ 2.5213e-02,  6.1303e-03, -2.0722e-02, -2.7696e-02,  2.1989e-02],\n",
      "          [-4.9958e-02,  2.7371e-02, -7.7092e-03, -3.9874e-02, -6.1590e-02],\n",
      "          [ 1.6205e-02,  1.2193e-02,  4.6695e-02, -9.1186e-03,  1.4002e-02]],\n",
      "\n",
      "         [[ 2.3488e-02, -2.2302e-02,  7.8565e-02,  5.8834e-03, -8.5379e-03],\n",
      "          [-2.5222e-02, -3.5760e-02,  9.8834e-03, -4.4069e-02,  3.7487e-02],\n",
      "          [ 6.0715e-03, -1.4675e-02, -6.8817e-02, -4.4554e-02, -2.3658e-02],\n",
      "          [-7.0761e-02, -5.5026e-02,  4.0152e-02,  4.5866e-02, -6.0698e-02],\n",
      "          [-4.3251e-02, -6.5748e-02, -7.8403e-02, -9.3075e-03,  3.7927e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7498e-02,  6.1844e-02, -1.7168e-04, -3.4259e-02, -3.9161e-04],\n",
      "          [ 8.0852e-02, -4.0471e-02,  2.4612e-02,  7.0489e-02, -7.8295e-02],\n",
      "          [-5.9952e-02, -7.8973e-02,  4.6608e-02,  3.0508e-03, -6.3400e-02],\n",
      "          [-4.3128e-02,  1.2084e-02,  2.5704e-02, -4.6936e-02,  3.6232e-02],\n",
      "          [ 2.3943e-02, -7.5342e-03,  2.2979e-02, -1.8110e-02,  3.3610e-02]],\n",
      "\n",
      "         [[ 4.8362e-02, -6.8240e-02,  3.8001e-02,  6.4352e-02,  2.3451e-03],\n",
      "          [-4.4695e-02, -6.1117e-03, -5.9726e-02,  3.8042e-02, -3.4152e-02],\n",
      "          [ 7.2448e-02,  5.9795e-02,  1.2813e-02, -1.9346e-02, -6.0004e-02],\n",
      "          [-3.7297e-02, -1.5923e-02, -8.9281e-03,  4.6287e-02,  2.8524e-02],\n",
      "          [ 4.7780e-02,  3.9012e-02,  7.1452e-02,  1.5970e-02, -1.4377e-02]],\n",
      "\n",
      "         [[-7.2048e-02,  2.1442e-03, -1.1992e-02, -2.8326e-02, -1.3482e-02],\n",
      "          [ 1.2417e-02, -2.1808e-02, -3.1639e-02, -3.4373e-02, -1.0684e-02],\n",
      "          [-6.3527e-03,  7.0085e-02,  1.0959e-02,  7.8600e-02, -6.6389e-02],\n",
      "          [ 6.3670e-02, -4.7254e-02,  5.9425e-02, -6.9980e-02,  1.9363e-02],\n",
      "          [-7.4877e-02,  6.0273e-02,  8.0185e-02,  2.6373e-02, -1.2240e-02]],\n",
      "\n",
      "         [[ 1.1241e-02,  3.7227e-03,  2.8039e-03, -3.0414e-03,  7.4398e-02],\n",
      "          [ 1.5744e-04,  1.0205e-02, -2.7961e-02, -7.8800e-02, -6.4916e-02],\n",
      "          [-5.7909e-02,  6.1619e-02, -2.2044e-02, -1.5056e-02,  7.6405e-03],\n",
      "          [ 7.7570e-02, -8.0574e-02, -1.6633e-02, -2.0652e-02, -3.0037e-02],\n",
      "          [-2.7422e-02, -4.6658e-02,  5.1795e-02, -7.4201e-02, -1.6225e-02]],\n",
      "\n",
      "         [[-1.0507e-02, -8.3243e-03,  6.8337e-03, -2.8315e-02,  2.6119e-02],\n",
      "          [ 7.5502e-02,  5.2215e-02, -8.8877e-03, -1.8663e-02, -6.4963e-02],\n",
      "          [-3.6870e-02,  2.2496e-02,  1.1584e-02, -4.9985e-02, -6.6688e-02],\n",
      "          [ 1.8749e-02, -5.5791e-02,  7.7463e-02, -3.1373e-02, -5.3195e-02],\n",
      "          [-3.5288e-02, -1.3872e-02, -6.0056e-02,  2.0373e-02,  7.9803e-02]],\n",
      "\n",
      "         [[-1.9680e-02,  6.6293e-02, -4.0522e-02, -6.1635e-03, -9.1035e-03],\n",
      "          [ 5.1643e-02, -4.1339e-02, -5.6442e-02,  7.0321e-02, -6.1421e-02],\n",
      "          [ 2.3870e-02, -3.2251e-02,  1.9237e-02,  4.7150e-02,  6.3360e-02],\n",
      "          [-7.0005e-02, -1.3219e-02,  5.0977e-02, -1.1495e-02, -7.7499e-02],\n",
      "          [ 3.7132e-02,  2.5558e-03,  9.8170e-03,  6.6215e-02,  6.4538e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.4706e-02,  4.3338e-02, -2.3708e-02, -8.0856e-02,  2.1777e-02],\n",
      "          [-7.2534e-02,  4.9000e-02,  7.8826e-02,  1.8190e-02,  8.1171e-02],\n",
      "          [-5.5846e-02, -7.9071e-02, -2.1030e-02,  2.4502e-02, -6.2647e-03],\n",
      "          [ 4.5328e-02, -3.9403e-02,  7.6106e-02,  2.5360e-02, -6.9347e-02],\n",
      "          [ 3.5570e-02, -6.1308e-02,  2.3459e-02, -1.7045e-02,  2.1717e-02]],\n",
      "\n",
      "         [[ 3.5852e-02,  3.4643e-02, -2.1145e-03, -7.8832e-02, -5.4619e-02],\n",
      "          [-3.5194e-02,  1.3296e-02,  4.4771e-02,  7.4432e-03, -5.0145e-02],\n",
      "          [ 7.9199e-02, -2.9534e-02, -7.7080e-02, -2.3305e-02,  2.8501e-02],\n",
      "          [-5.5384e-02,  1.9716e-02,  6.5317e-02,  7.9191e-02,  7.3802e-03],\n",
      "          [-6.5543e-02,  3.6851e-02, -3.5904e-02, -3.3933e-02, -9.3116e-03]],\n",
      "\n",
      "         [[-6.8987e-02,  1.5815e-02,  5.6287e-02, -7.4264e-02,  3.8634e-02],\n",
      "          [-3.1264e-02, -7.5477e-02,  5.1709e-02,  3.9593e-02,  6.4713e-02],\n",
      "          [ 5.5413e-02, -2.0092e-03, -5.5539e-02,  3.2843e-02,  4.0966e-02],\n",
      "          [ 3.5452e-02, -6.9041e-02, -2.7188e-02,  2.5495e-03, -3.4748e-02],\n",
      "          [ 1.6543e-02,  6.1498e-02, -1.1002e-03,  8.1476e-02, -3.4440e-02]],\n",
      "\n",
      "         [[ 4.9369e-02,  6.1057e-02,  6.1298e-04, -2.7125e-02,  4.5744e-02],\n",
      "          [ 1.5950e-02,  2.5369e-03, -2.0203e-02, -3.0325e-02,  3.1830e-02],\n",
      "          [-2.4082e-02,  6.6941e-02,  7.9115e-02, -6.3718e-02,  5.9478e-02],\n",
      "          [-6.1497e-02,  7.6637e-02,  7.6840e-02,  2.6048e-02, -1.1935e-02],\n",
      "          [-5.6377e-02,  7.9043e-02,  3.3182e-02, -5.4536e-02, -4.6279e-02]],\n",
      "\n",
      "         [[ 3.2204e-02, -6.7830e-02,  6.7533e-02,  3.5970e-03, -8.0604e-02],\n",
      "          [ 2.7595e-02, -1.4887e-02, -3.2063e-02,  1.0209e-02,  7.2748e-02],\n",
      "          [-5.6814e-02, -1.6344e-02, -7.0193e-02,  2.5903e-02, -7.1087e-02],\n",
      "          [ 4.1085e-02, -4.9929e-02, -5.8279e-02,  5.1235e-02,  6.2896e-02],\n",
      "          [-1.9090e-03,  7.5438e-02, -1.8853e-03,  2.3946e-02, -5.8524e-02]],\n",
      "\n",
      "         [[-2.3929e-02,  2.7374e-02, -6.9073e-02,  2.0731e-02, -3.6988e-03],\n",
      "          [-3.0607e-03,  6.9711e-02, -3.6164e-02,  6.4509e-02,  1.1042e-02],\n",
      "          [-1.4542e-02,  6.5354e-02, -2.1397e-02,  2.4475e-02,  2.4966e-02],\n",
      "          [-5.0790e-03, -7.8925e-02, -2.7237e-02, -5.1652e-02, -6.7220e-02],\n",
      "          [ 7.0954e-02,  4.1043e-02, -7.0046e-02,  1.7250e-02,  8.0924e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4002e-03,  2.2750e-02,  1.3263e-02, -9.4262e-04,  3.3588e-02],\n",
      "          [-4.7429e-03,  4.1787e-02,  1.7442e-02,  4.0542e-02,  4.0946e-02],\n",
      "          [-7.6581e-02,  1.6391e-02, -2.3286e-02, -6.0693e-02, -6.7577e-02],\n",
      "          [-8.1492e-02,  6.3284e-02,  7.1574e-02,  6.6675e-02,  2.1822e-02],\n",
      "          [ 6.1604e-03, -4.6870e-02, -4.3785e-02, -5.6727e-02,  1.4521e-02]],\n",
      "\n",
      "         [[-4.8451e-02, -7.3737e-03, -1.7172e-02,  7.9260e-02,  1.7105e-02],\n",
      "          [-1.5708e-02, -5.2839e-03, -3.0450e-02, -3.5142e-02,  1.3268e-02],\n",
      "          [ 3.8817e-02, -5.3897e-02,  1.4639e-02,  4.8200e-02,  2.2574e-02],\n",
      "          [ 7.4274e-02,  7.7201e-02, -4.7948e-02,  6.4823e-02,  6.7773e-02],\n",
      "          [ 7.2922e-02, -7.3691e-02, -7.1130e-02, -3.3799e-02,  2.9767e-02]],\n",
      "\n",
      "         [[ 3.5511e-02, -7.9888e-02,  4.8947e-02, -1.7081e-02,  9.2068e-03],\n",
      "          [-4.5654e-02, -2.1061e-02, -3.4405e-02, -9.4119e-03,  4.4480e-02],\n",
      "          [-6.8063e-02, -3.2247e-02,  4.8514e-02, -1.9426e-02, -3.8157e-02],\n",
      "          [-1.1740e-02, -7.2046e-02,  3.9002e-02,  7.0120e-02,  4.0945e-02],\n",
      "          [ 3.2760e-02,  7.5727e-02, -4.0227e-02,  1.6848e-02,  7.3404e-02]],\n",
      "\n",
      "         [[ 6.7028e-03, -6.6408e-02, -2.4659e-02, -1.8703e-02, -5.6562e-02],\n",
      "          [-3.0126e-04, -6.0020e-03,  2.4641e-03,  5.4224e-02,  2.3562e-02],\n",
      "          [ 2.9608e-02, -4.2725e-03,  8.8422e-03, -1.2401e-02,  6.6984e-02],\n",
      "          [-1.9664e-02, -2.5829e-02, -7.0606e-02,  3.3118e-02, -7.7709e-02],\n",
      "          [ 7.1892e-02, -5.9153e-02, -4.6724e-02, -4.2199e-02,  6.9970e-03]],\n",
      "\n",
      "         [[-5.3634e-02,  6.0848e-02, -2.1880e-02, -4.5651e-02,  5.8367e-02],\n",
      "          [ 2.8597e-02,  1.1653e-02,  3.8676e-02,  3.8083e-02, -7.6665e-03],\n",
      "          [-4.6574e-02,  6.1904e-02, -3.0270e-02, -5.6827e-02, -7.7522e-02],\n",
      "          [-1.2071e-02, -6.3989e-03,  7.7977e-02, -3.3960e-02, -6.0249e-03],\n",
      "          [ 6.4962e-03,  5.2673e-02,  4.0711e-02,  3.3434e-02,  1.9229e-03]],\n",
      "\n",
      "         [[ 1.9114e-02, -6.2652e-02,  2.8176e-02, -4.0312e-02,  9.4481e-03],\n",
      "          [ 4.7746e-02,  1.8496e-02,  1.6581e-02,  5.3775e-02, -6.1353e-02],\n",
      "          [-2.3746e-02, -3.6795e-02,  7.2341e-02,  7.8389e-02,  3.9866e-02],\n",
      "          [ 8.1544e-02,  3.3662e-02, -6.8375e-02, -3.0759e-02,  8.1129e-02],\n",
      "          [-6.2599e-02, -4.8567e-02,  2.3896e-02,  7.6429e-02, -4.0394e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1740e-02, -2.5507e-02,  6.2532e-02, -3.8727e-02, -3.4089e-02],\n",
      "          [ 2.7381e-02,  4.1998e-02, -7.8492e-02,  5.1243e-02, -6.0141e-02],\n",
      "          [-2.6690e-02,  1.5596e-02,  1.0734e-02,  7.0804e-02,  2.4206e-02],\n",
      "          [-3.1568e-03,  6.4883e-02, -1.2815e-02, -1.5328e-03, -1.3415e-02],\n",
      "          [ 4.4327e-02, -2.2333e-02, -4.6310e-02, -2.7068e-02,  1.0256e-02]],\n",
      "\n",
      "         [[-5.4079e-02, -1.3669e-02,  3.3523e-02,  5.3411e-03,  1.0741e-02],\n",
      "          [-8.1527e-02, -1.8731e-02,  6.5432e-02, -6.1277e-02, -7.2673e-02],\n",
      "          [-4.9110e-02, -2.1209e-02,  1.4928e-02, -3.3227e-02,  3.6872e-02],\n",
      "          [-6.8603e-02, -5.2059e-02, -3.0131e-02,  7.0358e-02, -8.5721e-03],\n",
      "          [ 7.1498e-02, -4.8666e-02, -3.3080e-02, -3.0630e-02, -6.8893e-02]],\n",
      "\n",
      "         [[ 2.1732e-02, -3.1395e-02,  7.1252e-02, -1.3451e-02, -4.6335e-02],\n",
      "          [ 5.3565e-02,  1.5056e-02, -4.7076e-03,  6.4897e-02,  7.0194e-02],\n",
      "          [ 2.5204e-02,  4.4514e-02,  1.1797e-02, -7.2395e-02, -5.4908e-02],\n",
      "          [-7.2760e-02, -2.0047e-02,  3.1246e-02,  7.2612e-02,  4.6086e-02],\n",
      "          [ 5.2752e-02, -2.2298e-03, -2.5395e-02, -5.1939e-02, -7.9121e-03]],\n",
      "\n",
      "         [[-2.5282e-02,  2.9129e-02, -7.4687e-02, -4.6928e-02, -1.0426e-02],\n",
      "          [ 1.1738e-02, -7.3310e-02,  3.0131e-02, -6.8332e-02,  4.4661e-02],\n",
      "          [-1.7140e-02,  3.7061e-02, -5.0189e-02, -7.7177e-03, -3.1654e-02],\n",
      "          [-2.8357e-02, -2.2924e-02, -2.9315e-02, -1.4445e-02, -7.6847e-04],\n",
      "          [ 1.4863e-03,  6.4551e-02, -7.9841e-02, -6.2174e-02,  9.5232e-03]],\n",
      "\n",
      "         [[ 2.6400e-02, -2.4610e-02, -3.1947e-02, -6.0706e-02, -3.9647e-02],\n",
      "          [-4.0118e-02,  6.3327e-02, -1.6865e-02,  2.8454e-02, -6.9431e-02],\n",
      "          [ 3.8067e-02, -3.5376e-02,  7.0621e-02, -3.8855e-02, -4.3458e-02],\n",
      "          [-5.5103e-02,  2.9735e-02,  4.6606e-02, -1.6797e-02,  2.9744e-02],\n",
      "          [ 7.7109e-02,  7.3372e-02, -6.6898e-02, -6.2666e-02, -4.7782e-02]],\n",
      "\n",
      "         [[ 1.5854e-02, -7.0941e-02,  8.1218e-02, -6.2427e-04, -6.5454e-02],\n",
      "          [-1.0965e-02,  6.8200e-02, -5.0442e-02, -4.0122e-02,  6.9003e-02],\n",
      "          [-6.0414e-02,  7.3997e-02, -5.2085e-02,  6.8871e-02,  7.7987e-02],\n",
      "          [-4.8084e-02, -2.4242e-03, -3.0333e-02,  8.8552e-03,  7.6770e-02],\n",
      "          [-5.4645e-02,  3.8196e-02, -1.7692e-02, -6.3474e-02,  2.2018e-02]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0538, -0.0019, -0.0689, -0.0361,  0.0787, -0.0312,  0.0477,  0.0710,\n",
      "         0.0661,  0.0250,  0.0765, -0.0376, -0.0538, -0.0123, -0.0273, -0.0603],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0402,  0.0470, -0.0100,  ...,  0.0211,  0.0137,  0.0437],\n",
      "        [-0.0209,  0.0484, -0.0375,  ..., -0.0135, -0.0338,  0.0127],\n",
      "        [-0.0010,  0.0192,  0.0064,  ...,  0.0272, -0.0001,  0.0490],\n",
      "        ...,\n",
      "        [-0.0028,  0.0213,  0.0026,  ...,  0.0286, -0.0385, -0.0036],\n",
      "        [ 0.0184, -0.0264, -0.0064,  ...,  0.0266, -0.0207,  0.0390],\n",
      "        [ 0.0447,  0.0134,  0.0453,  ..., -0.0253,  0.0047, -0.0222]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0084,  0.0477,  0.0462,  0.0343,  0.0488,  0.0031, -0.0476, -0.0185,\n",
      "         0.0071,  0.0109, -0.0083, -0.0109,  0.0423,  0.0176, -0.0367,  0.0063,\n",
      "        -0.0197,  0.0380,  0.0084, -0.0019, -0.0258, -0.0166,  0.0008,  0.0444,\n",
      "        -0.0336, -0.0229, -0.0425,  0.0398,  0.0437, -0.0003,  0.0363,  0.0132,\n",
      "         0.0306,  0.0478, -0.0027, -0.0024,  0.0139,  0.0011,  0.0086, -0.0139,\n",
      "         0.0364,  0.0499, -0.0245,  0.0173,  0.0438,  0.0378, -0.0395, -0.0464,\n",
      "        -0.0375,  0.0097, -0.0444,  0.0478,  0.0297, -0.0266,  0.0383, -0.0199,\n",
      "        -0.0135, -0.0482, -0.0055,  0.0167,  0.0359, -0.0328,  0.0245, -0.0350,\n",
      "         0.0033, -0.0017,  0.0164,  0.0008, -0.0484, -0.0066, -0.0051, -0.0146,\n",
      "        -0.0401,  0.0104, -0.0442, -0.0410,  0.0247, -0.0348, -0.0158, -0.0038,\n",
      "        -0.0128, -0.0166, -0.0138, -0.0326, -0.0070,  0.0265, -0.0299,  0.0462,\n",
      "         0.0131, -0.0368, -0.0212, -0.0214,  0.0390,  0.0458,  0.0027,  0.0228,\n",
      "         0.0227, -0.0308,  0.0086, -0.0013,  0.0450,  0.0417,  0.0302, -0.0220,\n",
      "         0.0002, -0.0314, -0.0385, -0.0267, -0.0091,  0.0443,  0.0265,  0.0477,\n",
      "         0.0240,  0.0380,  0.0367,  0.0066, -0.0268,  0.0430, -0.0046,  0.0107],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0769, -0.0266, -0.0699,  ...,  0.0661,  0.0462,  0.0549],\n",
      "        [-0.0894, -0.0521, -0.0062,  ...,  0.0111, -0.0635,  0.0865],\n",
      "        [ 0.0677,  0.0627,  0.0484,  ...,  0.0372, -0.0381,  0.0815],\n",
      "        ...,\n",
      "        [ 0.0525, -0.0847,  0.0305,  ...,  0.0405, -0.0466, -0.0547],\n",
      "        [-0.0572,  0.0564,  0.0608,  ...,  0.0736,  0.0409, -0.0373],\n",
      "        [ 0.0578,  0.0171, -0.0631,  ...,  0.0351, -0.0784, -0.0363]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 1.2094e-02, -7.2423e-02,  3.2471e-02,  6.3985e-02,  3.1006e-02,\n",
      "         4.9113e-02, -6.7994e-02, -2.3796e-03, -2.2283e-03, -6.2248e-03,\n",
      "        -1.5503e-02, -8.2741e-02,  6.1350e-02,  8.2335e-02, -6.0683e-02,\n",
      "        -2.3475e-02, -3.2006e-02,  4.9042e-02, -5.7679e-02,  3.5535e-03,\n",
      "        -2.3177e-02,  7.1410e-02, -8.6207e-02,  3.8172e-02, -5.7954e-02,\n",
      "        -4.8679e-02, -1.4568e-02, -6.1659e-02,  5.4400e-02,  8.9310e-05,\n",
      "         7.5234e-02,  6.6426e-02,  3.2819e-02,  3.4213e-02, -6.2910e-02,\n",
      "         5.1791e-03, -4.7098e-02, -5.7476e-03,  8.2252e-02,  4.0750e-02,\n",
      "        -7.5900e-03,  6.4169e-02, -7.8808e-02,  1.2250e-02,  4.8535e-02,\n",
      "         3.8204e-02, -4.6069e-03, -9.0384e-02, -7.0076e-02, -4.4127e-02,\n",
      "        -5.6612e-02,  6.8733e-02, -3.1878e-02,  7.3894e-02, -3.5021e-02,\n",
      "         8.9826e-02,  7.3276e-02,  7.5356e-02,  8.7425e-02, -3.5240e-02,\n",
      "        -5.3416e-02, -3.3929e-02, -3.8047e-02, -6.8657e-02,  7.0967e-02,\n",
      "        -4.8570e-03,  7.4709e-02, -5.2074e-03,  3.3347e-02, -8.3864e-02,\n",
      "        -3.8360e-02, -2.5940e-02, -5.8667e-02,  2.8922e-02,  8.4460e-03,\n",
      "        -2.2280e-02,  3.6570e-02, -4.9230e-02, -1.0455e-02, -4.9418e-02,\n",
      "        -2.2840e-03, -5.3946e-02,  3.4357e-02, -1.4637e-03],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-5.7694e-02, -9.3669e-02,  9.3223e-02,  8.9316e-02, -7.1965e-03,\n",
      "          3.3902e-02, -7.5491e-02, -5.9071e-02, -1.0690e-01, -1.0801e-01,\n",
      "          8.2789e-02, -1.0880e-01, -7.1987e-02,  2.1881e-02, -9.6874e-02,\n",
      "          4.5329e-02, -1.0158e-01,  5.7780e-02, -9.4801e-02, -1.5052e-02,\n",
      "         -1.0857e-01, -2.3139e-02, -2.5173e-02,  3.9357e-02,  9.5824e-02,\n",
      "         -6.0829e-02,  5.1706e-02,  1.3618e-02,  1.9566e-02,  2.6729e-02,\n",
      "         -9.5674e-02,  4.9173e-02,  1.6189e-02, -1.9561e-03, -6.1015e-02,\n",
      "         -4.1063e-02, -2.2193e-02, -1.0668e-01, -7.7226e-03,  8.1590e-02,\n",
      "          9.3493e-02,  3.9216e-02, -3.0678e-04,  5.6751e-02,  2.3539e-02,\n",
      "         -5.3824e-02,  1.0113e-01,  3.1347e-02, -5.9659e-02, -3.3825e-02,\n",
      "          1.0047e-01,  5.3947e-02,  1.6905e-02, -8.6864e-02,  3.4954e-02,\n",
      "          4.6063e-02, -8.3302e-02,  3.3399e-02,  5.4287e-02,  1.9790e-02,\n",
      "          9.9172e-03,  5.0707e-02,  7.5274e-03,  3.6065e-02, -1.0570e-02,\n",
      "          5.4521e-02, -2.8941e-02,  3.2170e-02,  3.2553e-02,  1.6175e-02,\n",
      "         -6.1685e-02,  4.8071e-02, -6.2160e-02, -4.1246e-02, -7.2586e-02,\n",
      "         -9.3525e-02, -7.6987e-02, -6.9540e-02,  7.4585e-02, -5.0524e-02,\n",
      "          1.4489e-02, -1.0534e-01,  8.2597e-02,  2.3167e-02],\n",
      "        [-9.4887e-02,  4.1777e-02, -1.8290e-02, -8.7410e-02, -7.9575e-02,\n",
      "         -2.6318e-02,  2.0077e-02,  7.6211e-02, -4.2112e-02, -5.3019e-02,\n",
      "          1.0212e-02, -8.8482e-02, -8.9817e-02,  2.0516e-03,  7.2912e-02,\n",
      "          1.0594e-01,  4.4282e-02, -1.2037e-02,  2.8386e-02,  1.0295e-01,\n",
      "         -9.1682e-02, -4.3744e-03, -9.3850e-02,  8.1534e-02,  3.4561e-02,\n",
      "         -1.7670e-02, -5.4215e-04, -1.0342e-01, -5.9147e-02,  8.3752e-02,\n",
      "         -7.4340e-02, -3.3392e-02, -5.2960e-02,  2.7259e-02,  3.3615e-02,\n",
      "          3.8819e-02,  9.5697e-02,  1.0524e-01, -3.2882e-02,  8.6572e-02,\n",
      "         -3.6024e-02, -1.0106e-01,  1.0860e-01, -9.6718e-02, -4.1790e-02,\n",
      "         -1.0461e-01, -1.3639e-02,  2.7004e-02, -5.8161e-02, -5.3863e-02,\n",
      "         -1.9145e-02, -2.1226e-02, -5.2371e-02,  1.3366e-02, -1.0129e-01,\n",
      "         -2.2930e-03,  7.9061e-02,  1.6979e-02,  5.1194e-02, -8.3944e-02,\n",
      "          9.1567e-02,  1.5130e-02,  4.6255e-03,  9.2449e-02, -2.4153e-02,\n",
      "         -5.1092e-02, -2.6148e-02,  1.2859e-03,  2.7449e-02,  8.9275e-02,\n",
      "          7.9851e-02, -5.0426e-03, -4.8571e-03, -9.7934e-02,  4.1341e-02,\n",
      "          8.1613e-02, -4.2309e-02, -4.9189e-02,  4.5251e-02,  3.6480e-02,\n",
      "          9.7993e-02, -9.0483e-02, -2.7266e-02, -7.3280e-02],\n",
      "        [-3.7449e-03,  5.7652e-02, -1.0102e-01,  4.3312e-02,  8.1260e-03,\n",
      "          6.7966e-02,  6.6634e-02, -2.2359e-02, -2.9756e-02,  5.8569e-03,\n",
      "          4.4873e-02,  8.3085e-02, -9.8160e-02, -7.4572e-02, -6.4059e-02,\n",
      "          9.9678e-02, -9.6188e-02,  9.7311e-02,  7.5770e-02,  3.0330e-02,\n",
      "         -1.4722e-03, -9.1269e-03, -3.1292e-02, -5.7980e-02, -8.0860e-02,\n",
      "         -7.7379e-02,  3.5961e-02, -5.3251e-02,  6.1666e-02, -9.9018e-02,\n",
      "          1.0748e-01, -8.3141e-02, -7.9124e-02,  6.3507e-04,  2.2459e-02,\n",
      "          8.7592e-02,  1.8469e-02,  8.8298e-02, -7.8234e-02,  3.2639e-02,\n",
      "         -1.1503e-02, -7.3038e-03,  6.7471e-02, -4.3387e-02, -6.4961e-02,\n",
      "          3.5502e-02, -7.6030e-02,  2.4094e-02,  6.1133e-02,  5.3809e-02,\n",
      "         -2.7468e-02,  7.5261e-02,  1.8897e-02,  7.8646e-02,  6.8662e-02,\n",
      "          6.5619e-02, -7.4239e-03,  4.1443e-02, -4.3958e-02,  9.5813e-02,\n",
      "         -3.2966e-02,  7.7234e-02,  7.4512e-02,  2.2638e-02,  3.4062e-02,\n",
      "          8.9965e-02,  1.0503e-01,  5.4347e-03, -8.2807e-03, -1.0168e-02,\n",
      "         -3.9447e-02, -7.3000e-02,  1.0562e-02, -2.0394e-02,  1.5465e-02,\n",
      "          4.7296e-02,  3.7217e-02,  1.2256e-02, -6.9317e-02,  1.4386e-02,\n",
      "         -8.5426e-03, -8.3644e-02, -1.0078e-01,  1.1570e-02],\n",
      "        [-6.4674e-02, -7.8782e-02, -6.3344e-02, -4.4076e-02, -4.8760e-02,\n",
      "         -5.7561e-02,  1.0838e-01,  8.9712e-02, -2.6003e-02,  9.9107e-02,\n",
      "         -7.6714e-02,  1.0026e-01, -7.1239e-02, -1.0732e-01,  6.6522e-02,\n",
      "          8.8690e-02, -9.5751e-02,  1.1222e-03, -9.4546e-02, -9.6765e-02,\n",
      "         -1.2538e-02, -2.6946e-02, -1.2101e-02,  8.8459e-02,  5.3974e-02,\n",
      "         -7.8564e-02, -2.4031e-02, -9.5773e-02,  8.5248e-02, -1.0760e-01,\n",
      "         -2.8695e-02, -8.8163e-02,  1.0876e-01, -2.4209e-02, -8.9746e-03,\n",
      "         -2.6755e-02, -5.7425e-02,  7.0369e-02, -5.6391e-02,  1.5234e-02,\n",
      "          8.1855e-02,  5.0069e-02,  6.0955e-02, -5.2651e-02, -4.3869e-02,\n",
      "          2.3595e-02, -1.0607e-01, -3.0389e-02,  2.3685e-02, -7.6246e-02,\n",
      "         -2.0342e-02, -9.1308e-02,  3.7529e-02,  1.0247e-01,  8.9747e-02,\n",
      "         -1.7758e-02,  7.9832e-02,  9.4741e-02, -9.8014e-02,  2.2868e-02,\n",
      "          5.1193e-02, -5.9128e-02,  8.6624e-02,  5.0847e-04,  1.9148e-02,\n",
      "          9.6078e-02, -6.5944e-02,  9.6803e-02, -5.5695e-02, -4.1689e-02,\n",
      "         -8.9674e-02,  9.6486e-02,  4.8708e-02,  5.4802e-02, -7.6878e-02,\n",
      "         -2.1334e-02,  9.3236e-02, -2.5912e-02,  9.0894e-02,  1.0667e-01,\n",
      "          7.6826e-02,  6.0654e-02, -4.8642e-02, -1.0523e-02],\n",
      "        [-9.8053e-02,  9.8628e-02,  6.7594e-02, -3.7574e-02, -2.1820e-02,\n",
      "         -5.1079e-02, -4.2680e-02, -7.0744e-02, -3.7267e-02,  8.4368e-02,\n",
      "         -2.5517e-02,  7.0460e-02,  6.4078e-02,  5.0897e-03, -9.4283e-02,\n",
      "         -9.8659e-02,  6.2043e-02, -5.3448e-02, -9.1443e-02,  1.2461e-02,\n",
      "          3.8201e-02, -4.1294e-03,  1.0609e-01,  8.4845e-02, -6.9864e-02,\n",
      "          2.4397e-02, -6.6491e-02, -7.3490e-02, -4.4817e-02,  8.2655e-02,\n",
      "         -9.7660e-02,  8.5226e-02, -7.1086e-02, -6.9724e-02, -6.3979e-02,\n",
      "          2.8727e-02, -4.6412e-02,  3.8213e-02, -8.3777e-02, -8.4933e-02,\n",
      "         -5.9096e-02,  1.0585e-01, -6.0297e-02, -8.0700e-02,  5.9224e-02,\n",
      "          7.9899e-02,  1.0195e-01, -5.5182e-02, -4.0427e-02,  7.5601e-02,\n",
      "         -3.8770e-02, -6.4344e-02,  8.0504e-02,  5.4584e-02,  4.4797e-02,\n",
      "         -6.7194e-02, -3.3325e-02,  5.3785e-02, -2.6858e-02, -1.7182e-02,\n",
      "          2.6442e-02, -3.9527e-02, -1.1170e-02,  1.9763e-02,  7.0305e-02,\n",
      "          6.5344e-03,  1.1747e-02, -9.0383e-03,  1.8238e-02,  4.7518e-02,\n",
      "          1.0248e-01, -3.7936e-02, -1.8375e-02,  7.7437e-02, -1.0021e-01,\n",
      "         -1.0521e-01, -5.3058e-02, -6.0349e-02,  3.1155e-02,  5.5396e-02,\n",
      "          6.9148e-02,  9.5853e-02,  9.3550e-02,  5.7745e-02],\n",
      "        [ 1.2356e-02, -1.8619e-02, -2.0428e-02, -6.5433e-02,  5.2737e-02,\n",
      "          4.9845e-02,  8.9356e-02,  9.7010e-02, -4.4697e-02,  3.2632e-02,\n",
      "         -9.0068e-02,  4.3242e-02,  2.7804e-02, -5.4284e-02,  1.5611e-02,\n",
      "          1.0794e-01,  8.1485e-02,  1.9966e-02,  7.6744e-02,  9.9363e-02,\n",
      "          8.6169e-02,  6.5487e-02,  5.5171e-02,  3.9669e-02, -9.1889e-02,\n",
      "         -3.5892e-02, -1.0011e-01,  6.6781e-02, -3.3031e-02, -7.8147e-02,\n",
      "          6.2446e-02,  1.0689e-01, -7.4632e-02, -7.5901e-02,  1.6189e-02,\n",
      "         -1.8199e-02, -3.0643e-02,  2.2432e-02, -9.7259e-02, -2.2787e-02,\n",
      "         -8.8341e-02, -1.2660e-02, -6.9050e-02, -4.8700e-02, -1.1348e-02,\n",
      "         -2.4865e-02, -8.0011e-04,  2.4224e-02, -1.9987e-02,  4.6883e-02,\n",
      "         -1.8592e-03,  2.1531e-02, -8.0398e-02, -9.8108e-02,  3.8908e-02,\n",
      "          6.0238e-02,  1.0550e-01,  8.2267e-02, -4.5960e-02,  4.6711e-02,\n",
      "         -6.9159e-02,  3.3379e-02,  7.9612e-02, -8.7583e-02,  1.2763e-02,\n",
      "         -5.0631e-02,  5.9408e-02, -3.6362e-02,  2.2046e-02, -1.1125e-02,\n",
      "         -4.6160e-02,  4.6602e-02, -6.3967e-02, -5.4153e-03,  7.6835e-02,\n",
      "         -1.0878e-01, -1.0998e-03,  5.3333e-02, -6.3708e-02, -1.0246e-01,\n",
      "          2.4869e-02,  4.7011e-02, -1.0165e-01,  9.1427e-02],\n",
      "        [-3.2065e-02, -3.2900e-03, -6.7280e-02,  5.9217e-02, -5.7563e-02,\n",
      "          1.8193e-02, -6.0960e-04, -3.4942e-03,  1.9375e-02,  4.6415e-02,\n",
      "         -1.0529e-01,  1.0642e-01, -8.6005e-02,  2.7228e-02,  3.3454e-02,\n",
      "         -2.7122e-02,  6.1697e-02, -7.9945e-02,  2.1638e-02, -8.1448e-02,\n",
      "          6.2023e-02, -1.8481e-02,  9.9556e-02,  8.6945e-03,  6.4490e-02,\n",
      "         -6.7127e-02,  2.3861e-03,  7.6596e-02,  3.9361e-02, -1.0260e-02,\n",
      "         -6.5749e-02,  4.4793e-05, -1.0772e-01,  1.0863e-01,  9.6974e-02,\n",
      "          8.5468e-02, -5.0277e-02, -3.3260e-02, -7.4525e-02, -8.2257e-02,\n",
      "          7.5156e-02, -2.3456e-02, -5.5456e-02, -2.7319e-02, -1.0870e-01,\n",
      "         -2.7002e-02, -5.6944e-02,  1.6851e-02, -4.4091e-02,  8.6624e-02,\n",
      "         -3.3218e-02, -5.8641e-02,  8.4369e-02,  8.0896e-02, -4.2481e-02,\n",
      "         -1.0298e-01, -7.3926e-02, -3.5445e-02,  6.8615e-03,  9.5294e-03,\n",
      "          8.3475e-02,  1.5385e-02,  1.1843e-02, -3.9476e-02, -3.4735e-02,\n",
      "         -8.7566e-02,  6.6175e-02, -5.4840e-02, -2.9918e-02, -4.2840e-02,\n",
      "          2.6427e-02,  4.4449e-02, -1.7109e-02,  6.2199e-03,  5.7939e-02,\n",
      "         -4.0200e-02,  8.6008e-02,  8.7615e-02,  1.9544e-02,  7.4782e-02,\n",
      "         -3.6336e-02,  4.4262e-03,  8.0435e-02, -4.6943e-02],\n",
      "        [ 1.8100e-02,  5.4380e-02, -4.4346e-02, -9.3632e-02,  9.5569e-02,\n",
      "         -2.8400e-02, -1.0617e-01, -1.0203e-01, -1.3972e-02, -4.7950e-02,\n",
      "          1.5947e-02, -9.6346e-02,  5.8692e-02,  4.6703e-02,  8.7906e-02,\n",
      "          9.2223e-02, -6.6738e-02, -3.3623e-02,  4.3848e-02, -4.2742e-02,\n",
      "         -1.4102e-02, -1.3040e-03,  6.2400e-02,  3.3480e-02,  6.1526e-03,\n",
      "          1.4608e-02,  9.2828e-02,  7.9385e-02,  9.4212e-02,  3.1683e-02,\n",
      "         -7.6130e-02, -8.7027e-02, -7.8917e-03, -4.9531e-02,  9.4664e-02,\n",
      "          5.9301e-02, -5.3398e-02,  6.1422e-02,  2.9481e-03, -5.2263e-02,\n",
      "         -4.7874e-02,  1.8124e-02,  4.3220e-03, -8.7564e-02, -1.0379e-01,\n",
      "         -9.2836e-02,  1.6812e-02, -1.8846e-02, -4.0249e-02, -8.5344e-02,\n",
      "          7.3596e-02,  5.6946e-02,  1.5769e-02,  9.3009e-02,  4.4629e-02,\n",
      "          6.1869e-02,  1.7178e-02,  1.0041e-01,  2.9436e-02, -1.1911e-02,\n",
      "          7.3633e-02, -1.6050e-02,  9.5259e-03,  1.2684e-02, -3.3037e-02,\n",
      "          1.0226e-02, -8.1687e-02,  1.0250e-01, -2.5465e-02, -5.1117e-02,\n",
      "          3.8836e-02,  9.8128e-02, -1.0509e-02, -4.8665e-02,  1.0298e-01,\n",
      "          2.6877e-03, -1.0667e-01,  5.4771e-02,  7.1304e-02,  4.1779e-02,\n",
      "         -1.0263e-02,  3.7544e-02,  1.6095e-02, -3.8168e-02],\n",
      "        [ 2.3060e-02,  5.9800e-02, -6.0958e-02,  4.3284e-02,  5.8283e-02,\n",
      "          3.3724e-02,  4.4311e-02, -2.6264e-02, -4.0619e-02,  1.9782e-02,\n",
      "          1.0358e-01,  1.6529e-02, -8.9768e-02, -9.0149e-02, -7.4888e-02,\n",
      "         -2.8592e-02, -1.0615e-01, -7.5232e-02,  9.1415e-02,  7.4896e-02,\n",
      "         -1.5069e-02, -9.3257e-03, -1.2460e-02, -3.0143e-02, -8.4232e-02,\n",
      "          2.1285e-02,  6.3868e-02, -9.3825e-02,  3.7884e-02,  3.5637e-02,\n",
      "         -9.6559e-02,  3.1076e-02,  4.6505e-02,  3.6274e-02, -5.8466e-02,\n",
      "         -1.8181e-02,  4.1830e-02,  1.0262e-01, -6.1558e-02,  4.5523e-02,\n",
      "         -1.0315e-01,  1.9257e-02, -3.4583e-02, -5.6076e-02, -9.0067e-02,\n",
      "         -8.4897e-02, -5.9046e-02,  6.0718e-02, -7.6640e-02,  5.8575e-02,\n",
      "          6.8996e-02, -1.3090e-02, -6.4410e-02,  8.8896e-02, -6.4846e-02,\n",
      "         -4.3667e-02, -6.8677e-02,  1.0259e-01, -5.1418e-02, -8.9880e-02,\n",
      "          7.8209e-02, -1.0004e-01,  4.9917e-02, -6.7482e-02,  2.1184e-02,\n",
      "          2.4668e-02, -9.7431e-02,  6.1137e-02,  8.7319e-02,  9.8068e-02,\n",
      "          5.6519e-02, -8.7757e-02, -5.7813e-02, -7.1959e-02,  2.9561e-02,\n",
      "         -3.0359e-02,  7.8725e-02,  7.0982e-02, -1.0170e-01, -5.7534e-02,\n",
      "          8.5660e-02, -3.6183e-03,  9.8779e-02,  9.4885e-02],\n",
      "        [ 7.4986e-03,  2.9697e-03, -9.6680e-02,  5.5641e-02, -9.1840e-02,\n",
      "         -3.1288e-02,  1.0806e-01,  3.8933e-02,  1.0433e-01,  2.5625e-02,\n",
      "         -1.0575e-01,  1.7538e-02,  7.1517e-02, -1.0137e-01, -3.8683e-02,\n",
      "         -7.8724e-02,  8.5343e-02,  9.4543e-03, -9.3828e-02,  8.4332e-03,\n",
      "          2.7823e-04,  3.4971e-02,  2.9210e-03,  9.0030e-02,  7.0355e-02,\n",
      "         -9.2403e-02,  6.3320e-02, -4.4913e-02, -1.0352e-01,  3.5072e-02,\n",
      "         -4.9412e-02,  7.4040e-02, -6.1287e-02,  8.5528e-02,  6.9774e-02,\n",
      "         -3.3510e-02,  1.4928e-02,  3.1412e-02, -2.6033e-02,  3.3666e-02,\n",
      "          2.4373e-02,  6.3014e-02, -1.2093e-02,  2.0504e-02, -3.3823e-03,\n",
      "         -1.1882e-02, -6.4400e-02,  2.9671e-02, -6.3009e-02,  5.7461e-02,\n",
      "          3.5112e-02, -5.7737e-02,  6.8932e-02,  6.7443e-02,  2.6408e-02,\n",
      "         -1.0052e-01, -1.2553e-02, -8.7787e-02, -2.6253e-02,  1.0533e-01,\n",
      "          5.2808e-02, -2.7449e-02,  9.9486e-02,  1.2915e-02,  8.4637e-02,\n",
      "         -9.9945e-02,  9.2221e-03, -2.0692e-02, -1.7085e-02, -7.1988e-02,\n",
      "         -5.5086e-02, -2.5815e-02,  9.3971e-02, -7.6506e-02, -5.8831e-02,\n",
      "          3.2916e-02,  9.8666e-02,  1.3400e-03, -9.0629e-02,  1.0090e-01,\n",
      "         -2.0617e-02, -1.5724e-02, -2.3356e-02, -6.2969e-02]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0742,  0.0656,  0.0663,  0.0013, -0.0184, -0.0724,  0.0746,  0.1077,\n",
      "        -0.0062,  0.0996], requires_grad=True)]\n",
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(params)\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65c9eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让我们尝试一个随机的 32x32 的输入。注意:这个网络 (LeNet）的期待输入是 32x32 的张量。如果使用 MNIST 数据集来训练这个网络，要把图片大小重新调整到 32x32。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36f100a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0726,  0.0555,  0.0635, -0.0446, -0.0538,  0.0115, -0.0260,  0.0781,\n",
      "         -0.0530,  0.0547]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cbceee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清零所有参数的梯度缓存，然后进行随机梯度的反向传播：\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f88c8d",
   "metadata": {},
   "source": [
    "# AlexNet网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25b98dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e2e9749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742df5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bianbian_ML] *",
   "language": "python",
   "name": "conda-env-bianbian_ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
